{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"border:solid blue 2px; padding: 20px\">\n",
    "<b> Reviewer Rules</b>\n",
    "\n",
    "Hi there ;) I will be using the following color boxes through the notebook code:\n",
    "    \n",
    "<div class=\"alert alert-success\" style=\"border-radius: 15px; box-shadow: 4px 4px 4px; border: 1px solid \">\n",
    "<b> Reviewer's comment</b>\n",
    "    \n",
    "Green means that it was nicely done.\n",
    "    \n",
    "</div>    \n",
    "    \n",
    "<div class=\"alert alert-warning\" style=\"border-radius: 15px; box-shadow: 4px 4px 4px; border: 1px solid \">\n",
    "<b> Reviewer's comment</b>\n",
    "\n",
    "Yellow color indicates what could be optimized. This is not necessary, but it will be great if you make changes to this project.\n",
    " \n",
    "</div>      \n",
    "    \n",
    "<div class=\"alert alert-danger\" style=\"border-radius: 15px; box-shadow: 4px 4px 4px; border: 1px solid \">\n",
    "<b> Reviewer's comment </b>\n",
    "\n",
    "Red is for things that must be done or changed for me to approve the project. If I rejected the project, you must look for this comments.\n",
    "    \n",
    "</div>    \n",
    "    \n",
    "**Please, use some color other than those listed to highlight answers to my comments.**\n",
    "I would also ask you **not to change, move or delete my comments** to make it easier for me to navigate during the next review."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"border:solid blue 2px; padding: 20px\">\n",
    "\n",
    "**Overall Summary of the Project**\n",
    "\n",
    "Dear Dinesh,\n",
    "\n",
    "I’ve thoroughly reviewed your project on predicting customer churn for Beta Bank. Your approach demonstrates a solid understanding of the fundamental steps in the machine learning pipeline, from data preprocessing to model evaluation. Below is a detailed assessment highlighting your strengths and outlining the essential areas that need attention to ensure your project meets all the required criteria.\n",
    "\n",
    "---\n",
    "\n",
    "**✅ Strengths**\n",
    "\n",
    "- **Data Cleaning and Preparation:**\n",
    "  - **Handling Missing Values:** You effectively addressed missing values in the `Tenure` column by imputing them with the median. This ensures that the dataset remains comprehensive without losing valuable information.\n",
    "  - **Dropping Irrelevant Columns:** Removing non-essential columns (`RowNumber`, `CustomerId`, `Surname`) helped in reducing noise and focusing the model on pertinent features.\n",
    "  \n",
    "- **Encoding Categorical Variables:**\n",
    "  - **One-Hot Encoding:** Applied one-hot encoding to categorical features (`Geography`, `Gender`) while avoiding the dummy variable trap by dropping the first category. This transformation is crucial for enabling the model to interpret categorical data effectively.\n",
    "\n",
    "- **Initial Model Training:**\n",
    "  - **Baseline Model:** Trained an initial Random Forest model to establish a performance benchmark. This provides a reference point to evaluate the impact of subsequent class imbalance handling techniques.\n",
    "\n",
    "- **Addressing Class Imbalance:**\n",
    "  - **Class Weighting:** Implemented class weighting in the Random Forest classifier to give more importance to the minority class (`Exited = 1`). This helps in mitigating the bias towards the majority class.\n",
    "\n",
    "- **Performance Metrics:**\n",
    "  - **Comprehensive Evaluation:** Calculated key metrics such as F1 score, accuracy, and AUC-ROC, providing a well-rounded assessment of the model’s performance.\n",
    "\n",
    "- **Clear Documentation:**\n",
    "  - **Structured Notebook:** Your notebook is well-organized with clear sections and explanations, making it easy to follow your analytical process and understand your decision-making.\n",
    "\n",
    "---\n",
    "\n",
    "**⚠️ Areas for Improvement**\n",
    "\n",
    "To ensure your project fully meets the requirements and achieves the best possible performance, please address the following essential areas:\n",
    "\n",
    "1. **Check for Duplicates in the Dataset:**\n",
    "   - **Why It Matters:** Duplicate records can skew the model’s learning process, leading to biased or inaccurate predictions.\n",
    "   - **How to Fix:**\n",
    "     ```python\n",
    "     # Check for duplicate rows\n",
    "     duplicates = data.duplicated()\n",
    "     print(f\"Number of duplicate rows: {duplicates.sum()}\")\n",
    "     \n",
    "     # Remove duplicate rows if any\n",
    "     data = data.drop_duplicates()\n",
    "     print(\"Duplicates removed.\")\n",
    "     ```\n",
    "     Ensure that after loading the data and before any preprocessing steps, you verify and remove any duplicate entries.\n",
    "\n",
    "2. **Examine the Distribution of the Target Variable in EDA:**\n",
    "   - **Why It Matters:** Understanding the distribution of the target variable (`Exited`) during Exploratory Data Analysis (EDA) provides insights into class imbalance and informs the choice of balancing techniques.\n",
    "   - **How to Fix:**\n",
    "     ```python\n",
    "     # Plot the distribution of the target variable\n",
    "     import matplotlib.pyplot as plt\n",
    "     import seaborn as sns\n",
    "     \n",
    "     sns.countplot(x='Exited', data=data)\n",
    "     plt.title('Distribution of Target Variable (Exited)')\n",
    "     plt.xlabel('Exited')\n",
    "     plt.ylabel('Count')\n",
    "     plt.show()\n",
    "     \n",
    "     # Print value counts\n",
    "     print(data['Exited'].value_counts())\n",
    "     ```\n",
    "     Incorporate this analysis into your EDA section to visualize and quantify the imbalance in the target classes.\n",
    "\n",
    "3. **Correctly Standardize Numerical Features:**\n",
    "   - **Why It Matters:** Standardizing features after splitting the data prevents data leakage, ensuring that the model generalizes well to unseen data.\n",
    "   - **How to Fix:**\n",
    "     ```python\n",
    "     from sklearn.preprocessing import StandardScaler\n",
    "     \n",
    "     # Split the data into training, validation, and test sets\n",
    "     features_train, features_temp, target_train, target_temp = train_test_split(\n",
    "         features, target, test_size=0.4, random_state=12345, stratify=target\n",
    "     )\n",
    "     features_valid, features_test, target_valid, target_test = train_test_split(\n",
    "         features_temp, target_temp, test_size=0.5, random_state=12345, stratify=target_temp\n",
    "     )\n",
    "     \n",
    "     # Initialize the scaler\n",
    "     scaler = StandardScaler()\n",
    "     \n",
    "     # Fit the scaler on the training data and transform\n",
    "     features_train[numerical] = scaler.fit_transform(features_train[numerical])\n",
    "     \n",
    "     # Transform validation and test data\n",
    "     features_valid[numerical] = scaler.transform(features_valid[numerical])\n",
    "     features_test[numerical] = scaler.transform(features_test[numerical])\n",
    "     ```\n",
    "     Ensure that scaling is performed **only** on the training set, and the same scaler is used to transform the validation and test sets.\n",
    "\n",
    "4. **Split the Data into Three Datasets (Training, Validation, Test):**\n",
    "   - **Why It Matters:** Having separate training, validation, and test sets allows for unbiased evaluation of the model’s performance and hyperparameter tuning.\n",
    "   - **How to Fix:**\n",
    "     ```python\n",
    "     from sklearn.model_selection import train_test_split\n",
    "     \n",
    "     # First split: Training set (60%) and Temporary set (40%)\n",
    "     features_train, features_temp, target_train, target_temp = train_test_split(\n",
    "         features, target, test_size=0.4, random_state=12345, stratify=target\n",
    "     )\n",
    "     \n",
    "     # Second split: Validation set (20%) and Test set (20%)\n",
    "     features_valid, features_test, target_valid, target_test = train_test_split(\n",
    "         features_temp, target_temp, test_size=0.5, random_state=12345, stratify=target_temp\n",
    "     )\n",
    "     \n",
    "     # Verify the splits\n",
    "     print(f\"Training set size: {features_train.shape[0]}\")\n",
    "     print(f\"Validation set size: {features_valid.shape[0]}\")\n",
    "     print(f\"Test set size: {features_test.shape[0]}\")\n",
    "     ```\n",
    "     Update your data splitting strategy to create distinct training, validation, and test sets, ensuring that each subset maintains the original class distribution through stratification.\n",
    "\n",
    "---\n",
    "\n",
    "**Conclusion**\n",
    "\n",
    "Your project demonstrates a commendable effort in building a predictive model for customer churn, effectively handling class imbalance through methods like class weighting and upsampling. Achieving an F1 score of **0.669** surpasses the project’s target of **0.59**, indicating that your model balances precision and recall well. Additionally, the high AUC-ROC score of **0.942** underscores your model’s strong capability in distinguishing between churned and retained customers.\n",
    "\n",
    "**Key Takeaways:**\n",
    "- **Effective Class Imbalance Handling:** Addressing the imbalance between churned and retained customers through upsampling significantly improved your model’s performance metrics.\n",
    "- **Robust Model Training:** Systematic hyperparameter tuning for the Random Forest classifier enhanced the model’s predictive power.\n",
    "- **Clear Documentation and Structured Workflow:** Your notebook is well-organized, making it easy to follow your analytical process.\n",
    "\n",
    "**Next Steps and Recommendations:**\n",
    "1. **Implement the Required Changes:** Address the four critical areas outlined above to ensure your model’s robustness and prevent potential pitfalls like data leakage.\n",
    "2. **Enhance Feature Interpretability:** Consider using tools like SHAP to gain deeper insights into feature contributions, providing actionable intelligence for Beta Bank’s retention strategies.\n",
    "3. **Explore Advanced Resampling Techniques:** Techniques such as SMOTE could further improve your model by generating synthetic samples for the minority class, potentially enhancing performance even more.\n",
    "4. **Validate with Cross-Validation:** Incorporate cross-validation techniques to obtain more reliable performance estimates and ensure your model generalizes well across different data subsets.\n",
    "\n",
    "By addressing these areas, you will solidify the foundation of your model, ensuring its reliability and effectiveness in real-world applications. Keep up the excellent work, and I’m confident that with these refinements, your project will be fully approved and highly valuable to Beta Bank’s customer retention efforts.\n",
    "\n",
    "Best regards,  \n",
    "Matías\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"border:solid blue 2px; padding: 20px\">\n",
    "\n",
    "**Overall Summary of the Project Iter 2**\n",
    "\n",
    "Great job with the 2nd submission!\n",
    "    \n",
    "There just a few changes that you must make in order for me to able to approve the project.\n",
    "    \n",
    "Please check the red boxes that says Iter 2 ;) You got it!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"border:solid blue 2px; padding: 20px\">\n",
    "\n",
    "**Overall Summary of the Project Iter 3**\n",
    "\n",
    "Good job on the 3rd submisison. The only thing left is for you to apply an up-sampling or down-sampling technique to the sum of features_train and features_valid when you train the last model. If you don't do that, you won't get an F1-Score higher than 0.59.\n",
    "\n",
    "Good luck! Please do contact a tutor if you need some more guidance ;)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"border:solid blue 2px; padding: 20px\">\n",
    "\n",
    "**Overall Summary of the Project Iter 4**\n",
    "\n",
    "Good job, Dinesh! The only thing you must do for me to approve is to fix the training of the final model. You are using the features_upsample (which is correct), but that features_upsample was created using only features_train. Remember, that the final model must be trained using both features_train + features_valid, and then apply the upsample or downsample.\n",
    "    \n",
    "Don't hesitate to contact a tutor if you need guidance! You got it :)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Predicting Customer Churn: A Machine Learning Approach for Beta Bank"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Introdction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Customer retention is a critical aspect of business success, particularly in the banking industry, where acquiring new customers is more expensive than retaining existing ones. This project focuses on developing a machine learning model to predict customer churn for Beta Bank, using historical customer behavior data. By identifying at-risk customers, the bank can implement targeted strategies to improve retention rates. The goal was to build a model with an F1 score of at least 0.59, ensuring a balance between precision and recall, while also evaluating its performance using metrics like AUC-ROC."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-success\" style=\"border-radius: 15px; box-shadow: 4px 4px 4px; border: 1px solid \">\n",
    "<b>   Reviewer's comment </b>\n",
    "\n",
    "Good introduction\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.utils import resample\n",
    "from sklearn.utils import shuffle\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import f1_score, accuracy_score, roc_auc_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load and Explore Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the data\n",
    "data = pd.read_csv('/datasets/Churn.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 10000 entries, 0 to 9999\n",
      "Data columns (total 14 columns):\n",
      " #   Column           Non-Null Count  Dtype  \n",
      "---  ------           --------------  -----  \n",
      " 0   RowNumber        10000 non-null  int64  \n",
      " 1   CustomerId       10000 non-null  int64  \n",
      " 2   Surname          10000 non-null  object \n",
      " 3   CreditScore      10000 non-null  int64  \n",
      " 4   Geography        10000 non-null  object \n",
      " 5   Gender           10000 non-null  object \n",
      " 6   Age              10000 non-null  int64  \n",
      " 7   Tenure           9091 non-null   float64\n",
      " 8   Balance          10000 non-null  float64\n",
      " 9   NumOfProducts    10000 non-null  int64  \n",
      " 10  HasCrCard        10000 non-null  int64  \n",
      " 11  IsActiveMember   10000 non-null  int64  \n",
      " 12  EstimatedSalary  10000 non-null  float64\n",
      " 13  Exited           10000 non-null  int64  \n",
      "dtypes: float64(3), int64(8), object(3)\n",
      "memory usage: 1.1+ MB\n",
      "None\n",
      "         RowNumber    CustomerId   CreditScore           Age       Tenure  \\\n",
      "count  10000.00000  1.000000e+04  10000.000000  10000.000000  9091.000000   \n",
      "mean    5000.50000  1.569094e+07    650.528800     38.921800     4.997690   \n",
      "std     2886.89568  7.193619e+04     96.653299     10.487806     2.894723   \n",
      "min        1.00000  1.556570e+07    350.000000     18.000000     0.000000   \n",
      "25%     2500.75000  1.562853e+07    584.000000     32.000000     2.000000   \n",
      "50%     5000.50000  1.569074e+07    652.000000     37.000000     5.000000   \n",
      "75%     7500.25000  1.575323e+07    718.000000     44.000000     7.000000   \n",
      "max    10000.00000  1.581569e+07    850.000000     92.000000    10.000000   \n",
      "\n",
      "             Balance  NumOfProducts    HasCrCard  IsActiveMember  \\\n",
      "count   10000.000000   10000.000000  10000.00000    10000.000000   \n",
      "mean    76485.889288       1.530200      0.70550        0.515100   \n",
      "std     62397.405202       0.581654      0.45584        0.499797   \n",
      "min         0.000000       1.000000      0.00000        0.000000   \n",
      "25%         0.000000       1.000000      0.00000        0.000000   \n",
      "50%     97198.540000       1.000000      1.00000        1.000000   \n",
      "75%    127644.240000       2.000000      1.00000        1.000000   \n",
      "max    250898.090000       4.000000      1.00000        1.000000   \n",
      "\n",
      "       EstimatedSalary        Exited  \n",
      "count     10000.000000  10000.000000  \n",
      "mean     100090.239881      0.203700  \n",
      "std       57510.492818      0.402769  \n",
      "min          11.580000      0.000000  \n",
      "25%       51002.110000      0.000000  \n",
      "50%      100193.915000      0.000000  \n",
      "75%      149388.247500      0.000000  \n",
      "max      199992.480000      1.000000  \n",
      "   RowNumber  CustomerId   Surname  CreditScore Geography  Gender  Age  \\\n",
      "0          1    15634602  Hargrave          619    France  Female   42   \n",
      "1          2    15647311      Hill          608     Spain  Female   41   \n",
      "2          3    15619304      Onio          502    France  Female   42   \n",
      "3          4    15701354      Boni          699    France  Female   39   \n",
      "4          5    15737888  Mitchell          850     Spain  Female   43   \n",
      "\n",
      "   Tenure    Balance  NumOfProducts  HasCrCard  IsActiveMember  \\\n",
      "0     2.0       0.00              1          1               1   \n",
      "1     1.0   83807.86              1          0               1   \n",
      "2     8.0  159660.80              3          1               0   \n",
      "3     1.0       0.00              2          0               0   \n",
      "4     2.0  125510.82              1          1               1   \n",
      "\n",
      "   EstimatedSalary  Exited  \n",
      "0        101348.88       1  \n",
      "1        112542.58       0  \n",
      "2        113931.57       1  \n",
      "3         93826.63       0  \n",
      "4         79084.10       0  \n"
     ]
    }
   ],
   "source": [
    "# Inspect the dataset\n",
    "print(data.info())\n",
    "print(data.describe())\n",
    "print(data.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Drop irrelevant columns\n",
    "data = data.drop(['RowNumber', 'CustomerId', 'Surname'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Handling missing values\n",
    "data['Tenure'] = data['Tenure'].fillna(data['Tenure'].median())  # Replace with the median\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are 9091 non null values out of 10000 entries in the **Tenure** column, so there are some missing values in that column, so I have replaced those missing values with median values."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Check for the Duplicate Values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of duplicate rows: 0\n",
      "Duplicates removed.\n"
     ]
    }
   ],
   "source": [
    "# Check for duplicate rows\n",
    "duplicates = data.duplicated()\n",
    "print(f\"Number of duplicate rows: {duplicates.sum()}\")\n",
    "\n",
    "# Remove duplicate rows if any\n",
    "data = data.drop_duplicates()\n",
    "print(\"Duplicates removed.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are no duplicate rows in our data\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-success\" style=\"border-radius: 15px; box-shadow: 4px 4px 4px; border: 1px solid \">\n",
    "<b>   Reviewer's comment </b>\n",
    "\n",
    "Good job filling missing values\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-success\" style=\"border-radius: 15px; box-shadow: 4px 4px 4px; border: 1px solid \">\n",
    "<b>   Reviewer's comment Iter 2</b>\n",
    "\n",
    "Good job, it's always good to check if there are duplicates\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Distribution of the Target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Target Variable Distribution:\n",
      "0    7963\n",
      "1    2037\n",
      "Name: Exited, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Check and plot the target variable distribution\n",
    "class_frequency = data['Exited'].value_counts()\n",
    "sns.countplot(x='Exited', data=data, palette='viridis')\n",
    "plt.title('Distribution of Target Variable (Exited)')\n",
    "plt.xlabel('Exited (0: Not Churned, 1: Churned)')\n",
    "plt.ylabel('Count')\n",
    "plt.grid(axis='y', linestyle='--', alpha=0.7)\n",
    "plt.show()\n",
    "\n",
    "# Print value counts\n",
    "print(\"Target Variable Distribution:\")\n",
    "print(class_frequency)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The analysis of the target variable, Exited, shows a significant class imbalance. Out of the total 10,000 customers, 7,963 have not churned (Exited = 0), while 2,037 have churned (Exited = 1). This imbalance indicates that the majority of customers are retained, which is common in many business scenarios. However, the disparity between the classes could cause machine learning models to be biased towards the majority class, leading to poor performance in predicting customer churn. \n",
    "Addressing this imbalance through techniques such as upsampling the minority class, downsampling the majority class, or using class weighting during training is crucial to ensure that the model effectively identifies customers at risk of churning."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-success\" style=\"border-radius: 15px; box-shadow: 4px 4px 4px; border: 1px solid \">\n",
    "<b>   Reviewer's comment Iter 2</b>\n",
    "\n",
    "Well done ;)\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-danger\" style=\"border-radius: 15px; box-shadow: 4px 4px 4px; border: 1px solid \">\n",
    "<b>   Reviewer's comment </b>\n",
    "\n",
    "Are there any duplicate values in the CustomerId column? That's something really important to check...\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-danger\" style=\"border-radius: 15px; box-shadow: 4px 4px 4px; border: 1px solid \">\n",
    "<b>   Reviewer's comment </b>\n",
    "\n",
    "What about the distribution of the target column? \n",
    "    \n",
    "<code># check and plot the balance of classes (churned vs not churned)\n",
    "class_frequency = df['exited'].value_counts()\n",
    "class_frequency.plot(kind='bar', title='Bank Customer Exits', xlabel='Count' , ylabel='Number of Customers',\n",
    "                    color='green', figsize=[4, 3], grid=True)\n",
    "class_frequency\n",
    "</code>\n",
    "    \n",
    "    \n",
    "Add conclusions about what you see.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Encoding Categorical Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.get_dummies(data, columns=['Geography', 'Gender'], drop_first=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are 2 categorical features, which are **Geography** and **Gender**, we need to be encoded using one-hot encoding or label encoding.\n",
    "Since the dataset is not very large, one-hot encoding is preferred to retain interpretability."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-success\" style=\"border-radius: 15px; box-shadow: 4px 4px 4px; border: 1px solid \">\n",
    "<b>   Reviewer's comment </b>\n",
    "\n",
    "Correct\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Splitting Features and Target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Separate the target variable (Exited) from the features.\n",
    "target = data['Exited']\n",
    "features = data.drop('Exited', axis=1)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Standardize Numerical Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_49/911452603.py:14: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  features_train[numerical] = scaler.fit_transform(features_train[numerical])\n",
      "/opt/conda/envs/python3/lib/python3.9/site-packages/pandas/core/indexing.py:1738: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  self._setitem_single_column(loc, value[:, i].tolist(), pi)\n",
      "/tmp/ipykernel_49/911452603.py:17: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  features_valid[numerical] = scaler.transform(features_valid[numerical])\n",
      "/opt/conda/envs/python3/lib/python3.9/site-packages/pandas/core/indexing.py:1738: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  self._setitem_single_column(loc, value[:, i].tolist(), pi)\n",
      "/tmp/ipykernel_49/911452603.py:18: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  features_test[numerical] = scaler.transform(features_test[numerical])\n",
      "/opt/conda/envs/python3/lib/python3.9/site-packages/pandas/core/indexing.py:1738: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  self._setitem_single_column(loc, value[:, i].tolist(), pi)\n"
     ]
    }
   ],
   "source": [
    "# Split the data\n",
    "features_train, features_temp, target_train, target_temp = train_test_split(\n",
    "    features, target, test_size=0.4, random_state=12345, stratify=target\n",
    ")\n",
    "features_valid, features_test, target_valid, target_test = train_test_split(\n",
    "    features_temp, target_temp, test_size=0.5, random_state=12345, stratify=target_temp\n",
    ")\n",
    "\n",
    "# Initialize the scaler\n",
    "scaler = StandardScaler()\n",
    "\n",
    "# Fit on training data and transform\n",
    "numerical = ['CreditScore', 'Age', 'Tenure', 'Balance', 'NumOfProducts', 'EstimatedSalary']\n",
    "features_train[numerical] = scaler.fit_transform(features_train[numerical])\n",
    "\n",
    "# Transform validation and test sets\n",
    "features_valid[numerical] = scaler.transform(features_valid[numerical])\n",
    "features_test[numerical] = scaler.transform(features_test[numerical])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-danger\" style=\"border-radius: 15px; box-shadow: 4px 4px 4px; border: 1px solid \">\n",
    "<b>   Reviewer's comment </b>\n",
    "\n",
    "The correct way to do this is:\n",
    "    \n",
    "1) We split the data\n",
    "2) We do the fit_transform of the \"scaler\" using the training dataset\n",
    "3) We apply it to both the test and validation tests (if there is one) \n",
    "    \n",
    "Here an example:\n",
    "<code>numeric = ['CreditScore', 'Age', 'Tenure', 'Balance', 'NumOfProducts', 'EstimatedSalary']\n",
    "scaler = StandardScaler()\n",
    "scaler.fit(features_train[numeric])\n",
    "features_train[numeric] = scaler.transform(features_train[numeric])\n",
    "features_valid[numeric] = scaler.transform(features_valid[numeric])\n",
    "features_test[numeric] = scaler.transform(features_test[numeric])</code>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Columns like CreditScore, Age, Tenure, Balance, NumOfProducts, and EstimatedSalary should be scaled for better model performance."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-success\" style=\"border-radius: 15px; box-shadow: 4px 4px 4px; border: 1px solid \">\n",
    "<b>   Reviewer's comment Iter 2</b>\n",
    "\n",
    "Correct, now it looks 10/10\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Splittng Data into Training, Validation, and Test Sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set size: 6000\n",
      "Validation set size: 2000\n",
      "Test set size: 2000\n"
     ]
    }
   ],
   "source": [
    "# Reuse the split and standardized data from previous cell\n",
    "# Simply verify the existing splits\n",
    "\n",
    "print(f\"Training set size: {features_train.shape[0]}\")\n",
    "print(f\"Validation set size: {features_valid.shape[0]}\")\n",
    "print(f\"Test set size: {features_test.shape[0]}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "No need to split and standardize the data again, the data was already splitted."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-success\" style=\"border-radius: 15px; box-shadow: 4px 4px 4px; border: 1px solid \">\n",
    "<b>   Reviewer's comment Iter 3</b>\n",
    "\n",
    "Well done\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-danger\" style=\"border-radius: 15px; box-shadow: 4px 4px 4px; border: 1px solid \">\n",
    "<b>   Reviewer's comment Iter 2</b>\n",
    "\n",
    "Good job! But you already splitted the dataset in the cell before, and you scaled the data. What you did here is: you splitted again but now you don't have the data scaled... check this again please\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-danger\" style=\"border-radius: 15px; box-shadow: 4px 4px 4px; border: 1px solid \">\n",
    "<b>   Reviewer's comment </b>\n",
    "\n",
    "It's good to have three datasets, remember: train, validation and test.\n",
    "    \n",
    "An example is the following:\n",
    "    \n",
    "<code># the first split gives us a training set of 60% and 'other' set of 40% to later be split\n",
    "features_train, features_other, target_train, target_other = train_test_split(features, target, test_size=0.4, random_state=12345)</code>\n",
    "\n",
    "<code># here the 'other' dataset, of 40% the original, is split in half to get is 20% for 'valid'  set, and 20% for 'test' set\n",
    "features_valid, features_test, target_valid, target_test = train_test_split(features_other, target_other, test_size=0.5, random_state=12345)</code>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training an Initial Model Without Addressing Imbalance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(random_state=12345)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Train a basic random forest model\n",
    "model = RandomForestClassifier(random_state=12345)\n",
    "model.fit(features_train, target_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make predictions\n",
    "predicted_valid = model.predict(features_valid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initial Model Metrics:\n",
      "F1 Score: 0.6126656848306332\n",
      "Accuracy: 0.8685\n",
      "AUC-ROC: 0.8623956177948565\n"
     ]
    }
   ],
   "source": [
    "# Evaluate metrics\n",
    "print(\"Initial Model Metrics:\")\n",
    "print(\"F1 Score:\", f1_score(target_valid, predicted_valid))\n",
    "print(\"Accuracy:\", accuracy_score(target_valid, predicted_valid))\n",
    "print(\"AUC-ROC:\", roc_auc_score(target_valid, model.predict_proba(features_valid)[:, 1]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Addressing the Class Imbalance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Class Weighted Model Metrics:\n",
      "F1 Score: 0.5783866057838661\n",
      "Accuracy: 0.8615\n",
      "AUC-ROC: 0.862270143610208\n"
     ]
    }
   ],
   "source": [
    "# Train a model with class weights\n",
    "model_weighted = RandomForestClassifier(random_state=12345, class_weight='balanced')\n",
    "model_weighted.fit(features_train, target_train)\n",
    "\n",
    "# Evaluate metrics\n",
    "predicted_valid_weighted = model_weighted.predict(features_valid)\n",
    "print(\"Class Weighted Model Metrics:\")\n",
    "print(\"F1 Score:\", f1_score(target_valid, predicted_valid_weighted))\n",
    "print(\"Accuracy:\", accuracy_score(target_valid, predicted_valid_weighted))\n",
    "print(\"AUC-ROC:\", roc_auc_score(target_valid, model_weighted.predict_proba(features_valid)[:, 1]))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Upsampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Combine training and validation sets before upsampling\n",
    "features_combined = pd.concat([features_train, features_valid])\n",
    "target_combined = pd.concat([target_train, target_valid])\n",
    "\n",
    "# Upsample the minority class\n",
    "features_zeros = features_combined[target_combined == 0]\n",
    "features_ones = features_combined[target_combined == 1]\n",
    "target_zeros = target_combined[target_combined == 0]\n",
    "target_ones = target_combined[target_combined == 1]\n",
    "\n",
    "features_upsampled = pd.concat([features_zeros] + [features_ones] * 4)\n",
    "target_upsampled = pd.concat([target_zeros] + [target_ones] * 4)\n",
    "\n",
    "# Shuffle the data\n",
    "features_upsampled, target_upsampled = shuffle(features_upsampled, target_upsampled, random_state=12345)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Down-Sampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Combine training and validation sets before downsampling\n",
    "features_combined = pd.concat([features_train, features_valid])\n",
    "target_combined = pd.concat([target_train, target_valid])\n",
    "\n",
    "# Downsample the majority class\n",
    "features_zeros = features_combined[target_combined == 0]\n",
    "features_ones = features_combined[target_combined == 1]\n",
    "target_zeros = target_combined[target_combined == 0]\n",
    "target_ones = target_combined[target_combined == 1]\n",
    "\n",
    "features_zeros_downsampled = features_zeros.sample(len(features_ones), random_state=12345)\n",
    "target_zeros_downsampled = target_zeros.sample(len(target_ones), random_state=12345)\n",
    "\n",
    "# Combine the downsampled majority class with the minority class\n",
    "features_downsampled = pd.concat([features_zeros_downsampled, features_ones])\n",
    "target_downsampled = pd.concat([target_zeros_downsampled, target_ones])\n",
    "\n",
    "# Shuffle the data\n",
    "features_downsampled, target_downsampled = shuffle(features_downsampled, target_downsampled, random_state=12345)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-warning\" style=\"border-radius: 15px; box-shadow: 4px 4px 4px; border: 1px solid \">\n",
    "<b>   Reviewer's comment </b>\n",
    "\n",
    "Good job. In practice, it's always better to down-sample instead of up-sample ;) Just for you to know for the future. You should get better results when doing down-sample (if you have enough data obviously).\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hyperparameter Tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Hyperparameters: {'n_estimators': 200, 'max_depth': 10, 'min_samples_split': 2, 'min_samples_leaf': 2, 'AUC-ROC': 0.8671266873583605}\n",
      "Best F1 Score: 0.6311713455953533\n"
     ]
    }
   ],
   "source": [
    "# Hyperparameter ranges\n",
    "n_estimators_range = [50, 100, 200]\n",
    "max_depth_range = [10, 20, None]\n",
    "min_samples_split_range = [2, 5]\n",
    "min_samples_leaf_range = [1, 2]\n",
    "\n",
    "# Track the best model and its metrics\n",
    "best_f1 = 0\n",
    "best_params = {}\n",
    "\n",
    "# Hyperparameter tuning\n",
    "for n_estimators in n_estimators_range:\n",
    "    for max_depth in max_depth_range:\n",
    "        for min_samples_split in min_samples_split_range:\n",
    "            for min_samples_leaf in min_samples_leaf_range:\n",
    "                # Train the model\n",
    "                model = RandomForestClassifier(\n",
    "                    n_estimators=n_estimators,\n",
    "                    max_depth=max_depth,\n",
    "                    min_samples_split=min_samples_split,\n",
    "                    min_samples_leaf=min_samples_leaf,\n",
    "                    random_state=12345,\n",
    "                )\n",
    "                model.fit(features_downsampled, target_downsampled)\n",
    "\n",
    "                # Evaluate the model\n",
    "                predicted_valid = model.predict(features_valid)\n",
    "                f1 = f1_score(target_valid, predicted_valid)\n",
    "                auc_roc = roc_auc_score(target_valid, model.predict_proba(features_valid)[:, 1])\n",
    "\n",
    "                # Update the best model if F1 improves\n",
    "                if f1 > best_f1:\n",
    "                    best_f1 = f1\n",
    "                    best_params = {\n",
    "                        'n_estimators': n_estimators,\n",
    "                        'max_depth': max_depth,\n",
    "                        'min_samples_split': min_samples_split,\n",
    "                        'min_samples_leaf': min_samples_leaf,\n",
    "                        'AUC-ROC': auc_roc,\n",
    "                    }\n",
    "\n",
    "# Print the best configuration and its metrics\n",
    "print(\"Best Hyperparameters:\", best_params)\n",
    "print(\"Best F1 Score:\", best_f1)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Best F1 Score:** 0.6311 (significantly above the target of 0.59).\n",
    "**AUC-ROC:** 0.8671, indicating strong model performance in distinguishing between classes.\n",
    "\n",
    "**Best Hyperparameters:**\n",
    "n_estimators: 200,\n",
    "max_depth: 10,\n",
    "min_samples_split: 2,\n",
    "min_samples_leaf: 2,\n",
    "\n",
    "This configuration has optimized the balance between precision and recall, demonstrating that the model can effectively handle class imbalance."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-success\" style=\"border-radius: 15px; box-shadow: 4px 4px 4px; border: 1px solid \">\n",
    "<b>   Reviewer's comment </b>\n",
    "\n",
    "Good job\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train the Final Model - with down-sampled data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(max_depth=15, min_samples_leaf=2, n_estimators=300,\n",
       "                       random_state=12345)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Train the final model on downsampled data\n",
    "final_model = RandomForestClassifier(\n",
    "    n_estimators=300,\n",
    "    max_depth=15,\n",
    "    min_samples_split=2,\n",
    "    min_samples_leaf=2,\n",
    "    random_state=12345\n",
    ")\n",
    "final_model.fit(features_downsampled, target_downsampled)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-danger\" style=\"border-radius: 15px; box-shadow: 4px 4px 4px; border: 1px solid \">\n",
    "<b>   Reviewer's comment Iter 4</b>\n",
    "\n",
    "The features_downsampled you are using, it comes from the features_train only, you should combine features_train and features_valid, then get the \"combined_features_downsampled\" and use that for the training. Since then, you need to test on the features_test.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-danger\" style=\"border-radius: 15px; box-shadow: 4px 4px 4px; border: 1px solid \">\n",
    "<b>   Reviewer's comment Iter 3</b>\n",
    "\n",
    "Where is the up-sampling or down-sampling? You are just training a random forest on normal data, without applying the up-sampling technique.\n",
    "    \n",
    "You must do that if you want the trained model to get you a F1 score higher than 0.59 in the next step.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-success\" style=\"border-radius: 15px; box-shadow: 4px 4px 4px; border: 1px solid \">\n",
    "<b>   Reviewer's comment </b>\n",
    "\n",
    "Good\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train the Final Model - with up-sampled data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(max_depth=15, min_samples_leaf=2, n_estimators=300,\n",
       "                       random_state=12345)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Train the final model on upsampled data\n",
    "final_model = RandomForestClassifier(\n",
    "    n_estimators=300,\n",
    "    max_depth=15,\n",
    "    min_samples_split=2,\n",
    "    min_samples_leaf=2,\n",
    "    random_state=12345\n",
    ")\n",
    "final_model.fit(features_upsampled, target_upsampled)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-danger\" style=\"border-radius: 15px; box-shadow: 4px 4px 4px; border: 1px solid \">\n",
    "<b>   Reviewer's comment Iter 4</b>\n",
    "\n",
    "The features_upsampled you are using, it comes from the features_train only, you should combine features_train and features_valid, then get the \"combined_features_upsampled\" and use that for the training. Since then, you need to test on the features_test.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test and Evaluate Final Model - with down-sampled data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final Model Metrics:\n",
      "F1 Score (Test): 0.586894586894587\n",
      "Accuracy (Test): 0.7825\n",
      "AUC-ROC (Test): 0.8562661274525681\n"
     ]
    }
   ],
   "source": [
    "# Test and Evaluate Final Model\n",
    "predicted_test = final_model.predict(features_test)\n",
    "print(\"Final Model Metrics:\")\n",
    "print(\"F1 Score (Test):\", f1_score(target_test, predicted_test))\n",
    "print(\"Accuracy (Test):\", accuracy_score(target_test, predicted_test))\n",
    "print(\"AUC-ROC (Test):\", roc_auc_score(target_test, final_model.predict_proba(features_test)[:, 1]))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-success\" style=\"border-radius: 15px; box-shadow: 4px 4px 4px; border: 1px solid \">\n",
    "<b>   Reviewer's comment Iter 4</b>\n",
    "\n",
    "Good job! The only thing left for you to do is to correctly train the final models with both features_train and features_valid combined, applying the upsampling/downsampling techniques ;) But with only the features_train, you already got 0.59! Nice\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-danger\" style=\"border-radius: 15px; box-shadow: 4px 4px 4px; border: 1px solid \">\n",
    "<b>   Reviewer's comment Iter 3</b>\n",
    "\n",
    "You are not achieving 0.59 here because you are using training the model using features_train and features_valid without doing the up or down-sampling.\n",
    "    \n",
    "You must up-sample or down-sample, then train, then you will get here a better F1-score.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-danger\" style=\"border-radius: 15px; box-shadow: 4px 4px 4px; border: 1px solid \">\n",
    "<b>   Reviewer's comment Iter 2</b>\n",
    "\n",
    "Here you must use the features_test set, since that's the one you are saving for the final testing and evaluation step. The idea is to use data that wasn't used during the training phase.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-warning\" style=\"border-radius: 15px; box-shadow: 4px 4px 4px; border: 1px solid \">\n",
    "<b>   Reviewer's comment </b>\n",
    "\n",
    "Here you should be using that 3rd dataset we prepared for testing purposes\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test and Evaluate Final Model - with up-sampled data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final Model Metrics:\n",
      "F1 Score (Test): 0.6080586080586079\n",
      "Accuracy (Test): 0.8395\n",
      "AUC-ROC (Test): 0.857547840598688\n"
     ]
    }
   ],
   "source": [
    "# Test and Evaluate Final Model\n",
    "predicted_test = final_model.predict(features_test)\n",
    "print(\"Final Model Metrics:\")\n",
    "print(\"F1 Score (Test):\", f1_score(target_test, predicted_test))\n",
    "print(\"Accuracy (Test):\", accuracy_score(target_test, predicted_test))\n",
    "print(\"AUC-ROC (Test):\", roc_auc_score(target_test, final_model.predict_proba(features_test)[:, 1]))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Analysis of Final Model Metrics**\n",
    "\n",
    "**F1 Score** (Test): 0.60\n",
    "This exceeds the project target of 0.59, indicating strong performance in balancing precision and recall.\n",
    "\n",
    "**Accuracy** (Test): 83%\n",
    "The model correctly classifies the majority of cases, demonstrating overall reliability.\n",
    "\n",
    "**AUC-ROC** (Test): 0.85\n",
    "This value shows the model’s excellent ability to distinguish between the two classes (Exited = 0 vs. 1). Values closer to 1 are ideal."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary of the Project\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "**Class Imbalance Handling:**\n",
    "The initial model struggled with class imbalance, as indicated by its lower F1 score.\n",
    "Addressing imbalance through upsampling significantly improved the F1 score while maintaining good AUC-ROC and accuracy.\n",
    "\n",
    "**Hyperparameter Tuning:**\n",
    "Optimizing the RandomForestClassifier with parameters:\n",
    "n_estimators: 300\n",
    "max_depth: 15\n",
    "min_samples_split: 2\n",
    "min_samples_leaf: 2\n",
    "This configuration yielded the best performance metrics, especially for the F1 score.\n",
    "\n",
    "**Final Model Performance:**\n",
    "The final model achieved F1: 0.591, Accuracy: 83%, and AUC-ROC: 0.85, showcasing its ability to handle the imbalanced dataset effectively and predict customer churn accurately."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Overall Conclusion"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The project successfully developed a predictive model to identify customers likely to churn from Beta Bank, achieving an F1 score of 0.60 on the test set, exceeds the target of 0.59. Addressing the class imbalance through upsampling significantly improved model performance compared to the baseline and class-weighting approaches. After hyperparameter tuning, the best RandomForestClassifier configuration delivered strong results with an accuracy of 83% and an AUC-ROC of 0.85, indicating excellent discriminatory power between churned and non-churned customers. This model provides Beta Bank with a reliable tool to proactively identify at-risk customers and implement targeted retention strategies, ultimately helping to reduce customer churn and enhance overall business performance."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-success\" style=\"border-radius: 15px; box-shadow: 4px 4px 4px; border: 1px solid \">\n",
    "<b>   Reviewer's comment </b>\n",
    "\n",
    "Good job, you just need a few minor changes ;)\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "ExecuteTimeLog": [
   {
    "duration": 3,
    "start_time": "2025-01-25T18:18:52.163Z"
   },
   {
    "duration": 312,
    "start_time": "2025-01-25T18:19:12.417Z"
   },
   {
    "duration": 31,
    "start_time": "2025-01-25T18:19:55.788Z"
   },
   {
    "duration": 36,
    "start_time": "2025-01-25T18:20:08.663Z"
   },
   {
    "duration": 4,
    "start_time": "2025-01-25T18:23:11.010Z"
   },
   {
    "duration": 3,
    "start_time": "2025-01-25T18:24:00.656Z"
   },
   {
    "duration": 2,
    "start_time": "2025-01-25T18:24:09.524Z"
   },
   {
    "duration": 4,
    "start_time": "2025-01-25T18:24:25.487Z"
   },
   {
    "duration": 8,
    "start_time": "2025-01-25T18:28:19.840Z"
   },
   {
    "duration": 8,
    "start_time": "2025-01-25T18:29:43.180Z"
   },
   {
    "duration": 4,
    "start_time": "2025-01-25T18:33:55.833Z"
   },
   {
    "duration": 457,
    "start_time": "2025-01-25T18:35:02.758Z"
   },
   {
    "duration": 17,
    "start_time": "2025-01-25T18:35:27.868Z"
   },
   {
    "duration": 3,
    "start_time": "2025-01-25T18:38:20.356Z"
   },
   {
    "duration": 14,
    "start_time": "2025-01-25T18:38:45.144Z"
   },
   {
    "duration": 6,
    "start_time": "2025-01-25T18:42:15.918Z"
   },
   {
    "duration": 11,
    "start_time": "2025-01-25T18:45:53.449Z"
   },
   {
    "duration": 3,
    "start_time": "2025-01-25T18:48:36.245Z"
   },
   {
    "duration": 2,
    "start_time": "2025-01-25T18:49:22.546Z"
   },
   {
    "duration": 226,
    "start_time": "2025-01-25T18:50:07.916Z"
   },
   {
    "duration": 3,
    "start_time": "2025-01-25T18:52:58.911Z"
   },
   {
    "duration": 10,
    "start_time": "2025-01-25T18:53:05.095Z"
   },
   {
    "duration": 33,
    "start_time": "2025-01-25T18:57:05.645Z"
   },
   {
    "duration": 2,
    "start_time": "2025-01-25T19:00:45.658Z"
   },
   {
    "duration": 682,
    "start_time": "2025-01-25T19:01:44.239Z"
   },
   {
    "duration": 42,
    "start_time": "2025-01-25T19:02:03.560Z"
   },
   {
    "duration": 44,
    "start_time": "2025-01-25T19:02:14.496Z"
   },
   {
    "duration": 2,
    "start_time": "2025-01-25T19:03:01.868Z"
   },
   {
    "duration": 743,
    "start_time": "2025-01-25T19:04:05.939Z"
   },
   {
    "duration": 1081,
    "start_time": "2025-01-25T19:05:01.916Z"
   },
   {
    "duration": 41247,
    "start_time": "2025-01-25T19:32:52.182Z"
   },
   {
    "duration": 1428,
    "start_time": "2025-01-25T19:40:31.107Z"
   },
   {
    "duration": 19,
    "start_time": "2025-01-25T19:41:37.943Z"
   },
   {
    "duration": 3,
    "start_time": "2025-01-25T19:42:35.885Z"
   },
   {
    "duration": 19,
    "start_time": "2025-01-25T19:42:35.892Z"
   },
   {
    "duration": 36,
    "start_time": "2025-01-25T19:42:35.913Z"
   },
   {
    "duration": 5,
    "start_time": "2025-01-25T19:42:35.951Z"
   },
   {
    "duration": 29,
    "start_time": "2025-01-25T19:42:35.958Z"
   },
   {
    "duration": 8,
    "start_time": "2025-01-25T19:42:35.989Z"
   },
   {
    "duration": 5,
    "start_time": "2025-01-25T19:42:35.999Z"
   },
   {
    "duration": 15,
    "start_time": "2025-01-25T19:42:36.006Z"
   },
   {
    "duration": 6,
    "start_time": "2025-01-25T19:42:36.023Z"
   },
   {
    "duration": 5,
    "start_time": "2025-01-25T19:42:36.030Z"
   },
   {
    "duration": 710,
    "start_time": "2025-01-25T19:42:36.037Z"
   },
   {
    "duration": 49,
    "start_time": "2025-01-25T19:42:36.749Z"
   },
   {
    "duration": 47,
    "start_time": "2025-01-25T19:42:36.800Z"
   },
   {
    "duration": 760,
    "start_time": "2025-01-25T19:42:36.849Z"
   },
   {
    "duration": 1105,
    "start_time": "2025-01-25T19:42:37.612Z"
   },
   {
    "duration": 41950,
    "start_time": "2025-01-25T19:42:38.719Z"
   },
   {
    "duration": 1452,
    "start_time": "2025-01-25T19:43:20.671Z"
   },
   {
    "duration": 15,
    "start_time": "2025-01-25T19:43:22.125Z"
   },
   {
    "duration": 71,
    "start_time": "2025-01-25T19:47:08.806Z"
   },
   {
    "duration": 72,
    "start_time": "2025-01-25T19:47:31.639Z"
   },
   {
    "duration": 117,
    "start_time": "2025-01-25T19:47:50.038Z"
   },
   {
    "duration": 2,
    "start_time": "2025-01-25T19:52:07.691Z"
   },
   {
    "duration": 823,
    "start_time": "2025-01-25T20:01:47.833Z"
   },
   {
    "duration": 17,
    "start_time": "2025-01-25T20:01:48.659Z"
   },
   {
    "duration": 38,
    "start_time": "2025-01-25T20:01:48.678Z"
   },
   {
    "duration": 4,
    "start_time": "2025-01-25T20:01:48.718Z"
   },
   {
    "duration": 4,
    "start_time": "2025-01-25T20:01:48.724Z"
   },
   {
    "duration": 7,
    "start_time": "2025-01-25T20:01:48.729Z"
   },
   {
    "duration": 4,
    "start_time": "2025-01-25T20:01:48.738Z"
   },
   {
    "duration": 50,
    "start_time": "2025-01-25T20:01:48.744Z"
   },
   {
    "duration": 6,
    "start_time": "2025-01-25T20:01:48.795Z"
   },
   {
    "duration": 9,
    "start_time": "2025-01-25T20:01:48.802Z"
   },
   {
    "duration": 704,
    "start_time": "2025-01-25T20:01:48.813Z"
   },
   {
    "duration": 40,
    "start_time": "2025-01-25T20:01:49.519Z"
   },
   {
    "duration": 57,
    "start_time": "2025-01-25T20:01:49.560Z"
   },
   {
    "duration": 751,
    "start_time": "2025-01-25T20:01:49.621Z"
   },
   {
    "duration": 1077,
    "start_time": "2025-01-25T20:01:50.374Z"
   },
   {
    "duration": 41768,
    "start_time": "2025-01-25T20:01:51.454Z"
   },
   {
    "duration": 1439,
    "start_time": "2025-01-25T20:02:33.224Z"
   },
   {
    "duration": 285,
    "start_time": "2025-01-25T20:02:34.666Z"
   },
   {
    "duration": 75,
    "start_time": "2025-01-25T20:03:00.934Z"
   },
   {
    "duration": 118,
    "start_time": "2025-01-25T20:03:13.158Z"
   },
   {
    "duration": 791,
    "start_time": "2025-01-25T23:50:09.490Z"
   },
   {
    "duration": 25,
    "start_time": "2025-01-25T23:50:10.284Z"
   },
   {
    "duration": 34,
    "start_time": "2025-01-25T23:50:10.311Z"
   },
   {
    "duration": 4,
    "start_time": "2025-01-25T23:50:10.347Z"
   },
   {
    "duration": 3,
    "start_time": "2025-01-25T23:50:10.354Z"
   },
   {
    "duration": 7,
    "start_time": "2025-01-25T23:50:10.359Z"
   },
   {
    "duration": 4,
    "start_time": "2025-01-25T23:50:10.368Z"
   },
   {
    "duration": 15,
    "start_time": "2025-01-25T23:50:10.373Z"
   },
   {
    "duration": 6,
    "start_time": "2025-01-25T23:50:10.390Z"
   },
   {
    "duration": 37,
    "start_time": "2025-01-25T23:50:10.398Z"
   },
   {
    "duration": 696,
    "start_time": "2025-01-25T23:50:10.437Z"
   },
   {
    "duration": 41,
    "start_time": "2025-01-25T23:50:11.135Z"
   },
   {
    "duration": 58,
    "start_time": "2025-01-25T23:50:11.178Z"
   },
   {
    "duration": 773,
    "start_time": "2025-01-25T23:50:11.239Z"
   },
   {
    "duration": 1097,
    "start_time": "2025-01-25T23:50:12.014Z"
   },
   {
    "duration": 41537,
    "start_time": "2025-01-25T23:50:13.113Z"
   },
   {
    "duration": 1469,
    "start_time": "2025-01-25T23:50:54.652Z"
   },
   {
    "duration": 128,
    "start_time": "2025-01-25T23:50:56.123Z"
   },
   {
    "duration": 3,
    "start_time": "2025-01-25T23:51:37.864Z"
   },
   {
    "duration": 16,
    "start_time": "2025-01-25T23:51:37.869Z"
   },
   {
    "duration": 37,
    "start_time": "2025-01-25T23:51:37.887Z"
   },
   {
    "duration": 5,
    "start_time": "2025-01-25T23:51:37.926Z"
   },
   {
    "duration": 4,
    "start_time": "2025-01-25T23:51:37.934Z"
   },
   {
    "duration": 11,
    "start_time": "2025-01-25T23:51:37.940Z"
   },
   {
    "duration": 5,
    "start_time": "2025-01-25T23:51:37.953Z"
   },
   {
    "duration": 14,
    "start_time": "2025-01-25T23:51:37.959Z"
   },
   {
    "duration": 5,
    "start_time": "2025-01-25T23:51:37.975Z"
   },
   {
    "duration": 4,
    "start_time": "2025-01-25T23:51:37.982Z"
   },
   {
    "duration": 719,
    "start_time": "2025-01-25T23:51:37.988Z"
   },
   {
    "duration": 51,
    "start_time": "2025-01-25T23:51:38.709Z"
   },
   {
    "duration": 47,
    "start_time": "2025-01-25T23:51:38.764Z"
   },
   {
    "duration": 760,
    "start_time": "2025-01-25T23:51:38.813Z"
   },
   {
    "duration": 1103,
    "start_time": "2025-01-25T23:51:39.575Z"
   },
   {
    "duration": 41505,
    "start_time": "2025-01-25T23:51:40.680Z"
   },
   {
    "duration": 1445,
    "start_time": "2025-01-25T23:52:22.187Z"
   },
   {
    "duration": 125,
    "start_time": "2025-01-25T23:52:23.634Z"
   },
   {
    "duration": 6,
    "start_time": "2025-01-26T00:05:41.910Z"
   },
   {
    "duration": 161,
    "start_time": "2025-01-27T00:03:09.243Z"
   },
   {
    "duration": 823,
    "start_time": "2025-01-27T00:03:17.091Z"
   },
   {
    "duration": 30,
    "start_time": "2025-01-27T00:03:17.916Z"
   },
   {
    "duration": 35,
    "start_time": "2025-01-27T00:03:17.948Z"
   },
   {
    "duration": 5,
    "start_time": "2025-01-27T00:03:17.985Z"
   },
   {
    "duration": 5,
    "start_time": "2025-01-27T00:03:17.991Z"
   },
   {
    "duration": 10,
    "start_time": "2025-01-27T00:03:17.997Z"
   },
   {
    "duration": 34,
    "start_time": "2025-01-27T00:03:18.009Z"
   },
   {
    "duration": 4,
    "start_time": "2025-01-27T00:03:18.047Z"
   },
   {
    "duration": 15,
    "start_time": "2025-01-27T00:03:18.053Z"
   },
   {
    "duration": 5,
    "start_time": "2025-01-27T00:03:18.070Z"
   },
   {
    "duration": 5,
    "start_time": "2025-01-27T00:03:18.077Z"
   },
   {
    "duration": 728,
    "start_time": "2025-01-27T00:03:18.084Z"
   },
   {
    "duration": 49,
    "start_time": "2025-01-27T00:03:18.813Z"
   },
   {
    "duration": 49,
    "start_time": "2025-01-27T00:03:18.864Z"
   },
   {
    "duration": 768,
    "start_time": "2025-01-27T00:03:18.916Z"
   },
   {
    "duration": 1095,
    "start_time": "2025-01-27T00:03:19.686Z"
   },
   {
    "duration": 41505,
    "start_time": "2025-01-27T00:03:20.782Z"
   },
   {
    "duration": 1461,
    "start_time": "2025-01-27T00:04:02.289Z"
   },
   {
    "duration": 121,
    "start_time": "2025-01-27T00:04:03.753Z"
   },
   {
    "duration": 2037,
    "start_time": "2025-01-27T00:11:46.759Z"
   },
   {
    "duration": 115,
    "start_time": "2025-01-27T00:12:16.559Z"
   },
   {
    "duration": 308,
    "start_time": "2025-01-27T00:22:51.571Z"
   },
   {
    "duration": 21,
    "start_time": "2025-01-27T00:23:10.040Z"
   },
   {
    "duration": 35,
    "start_time": "2025-01-27T00:23:19.656Z"
   },
   {
    "duration": 167,
    "start_time": "2025-01-27T01:28:38.260Z"
   },
   {
    "duration": 2707,
    "start_time": "2025-01-27T01:28:50.257Z"
   },
   {
    "duration": 28,
    "start_time": "2025-01-27T01:28:52.966Z"
   },
   {
    "duration": 34,
    "start_time": "2025-01-27T01:28:52.996Z"
   },
   {
    "duration": 3,
    "start_time": "2025-01-27T01:28:53.032Z"
   },
   {
    "duration": 5,
    "start_time": "2025-01-27T01:28:53.036Z"
   },
   {
    "duration": 10,
    "start_time": "2025-01-27T01:28:53.043Z"
   },
   {
    "duration": 178,
    "start_time": "2025-01-27T01:28:53.055Z"
   },
   {
    "duration": 9,
    "start_time": "2025-01-27T01:28:53.235Z"
   },
   {
    "duration": 5,
    "start_time": "2025-01-27T01:28:53.246Z"
   },
   {
    "duration": 39,
    "start_time": "2025-01-27T01:28:53.254Z"
   },
   {
    "duration": 12,
    "start_time": "2025-01-27T01:28:53.295Z"
   },
   {
    "duration": 573,
    "start_time": "2025-01-27T01:28:53.309Z"
   },
   {
    "duration": 33,
    "start_time": "2025-01-27T01:28:53.884Z"
   },
   {
    "duration": 51,
    "start_time": "2025-01-27T01:28:53.919Z"
   },
   {
    "duration": 608,
    "start_time": "2025-01-27T01:28:53.972Z"
   },
   {
    "duration": 878,
    "start_time": "2025-01-27T01:28:54.582Z"
   },
   {
    "duration": 33071,
    "start_time": "2025-01-27T01:28:55.462Z"
   },
   {
    "duration": 1183,
    "start_time": "2025-01-27T01:29:28.535Z"
   },
   {
    "duration": 108,
    "start_time": "2025-01-27T01:29:29.720Z"
   },
   {
    "duration": 26,
    "start_time": "2025-01-27T01:32:08.289Z"
   },
   {
    "duration": 25,
    "start_time": "2025-01-27T01:33:06.193Z"
   },
   {
    "duration": 1004,
    "start_time": "2025-01-27T01:35:38.706Z"
   },
   {
    "duration": 16,
    "start_time": "2025-01-27T01:35:39.712Z"
   },
   {
    "duration": 44,
    "start_time": "2025-01-27T01:35:39.729Z"
   },
   {
    "duration": 4,
    "start_time": "2025-01-27T01:35:39.774Z"
   },
   {
    "duration": 3,
    "start_time": "2025-01-27T01:35:39.780Z"
   },
   {
    "duration": 11,
    "start_time": "2025-01-27T01:35:39.785Z"
   },
   {
    "duration": 128,
    "start_time": "2025-01-27T01:35:39.797Z"
   },
   {
    "duration": 8,
    "start_time": "2025-01-27T01:35:39.928Z"
   },
   {
    "duration": 4,
    "start_time": "2025-01-27T01:35:39.938Z"
   },
   {
    "duration": 257,
    "start_time": "2025-01-27T01:35:39.945Z"
   },
   {
    "duration": 0,
    "start_time": "2025-01-27T01:35:40.204Z"
   },
   {
    "duration": 0,
    "start_time": "2025-01-27T01:35:40.205Z"
   },
   {
    "duration": 0,
    "start_time": "2025-01-27T01:35:40.207Z"
   },
   {
    "duration": 0,
    "start_time": "2025-01-27T01:35:40.208Z"
   },
   {
    "duration": 0,
    "start_time": "2025-01-27T01:35:40.210Z"
   },
   {
    "duration": 0,
    "start_time": "2025-01-27T01:35:40.212Z"
   },
   {
    "duration": 0,
    "start_time": "2025-01-27T01:35:40.213Z"
   },
   {
    "duration": 0,
    "start_time": "2025-01-27T01:35:40.215Z"
   },
   {
    "duration": 0,
    "start_time": "2025-01-27T01:35:40.216Z"
   },
   {
    "duration": 25,
    "start_time": "2025-01-27T01:39:07.787Z"
   },
   {
    "duration": 995,
    "start_time": "2025-01-27T01:40:18.053Z"
   },
   {
    "duration": 21,
    "start_time": "2025-01-27T01:40:19.050Z"
   },
   {
    "duration": 35,
    "start_time": "2025-01-27T01:40:19.072Z"
   },
   {
    "duration": 3,
    "start_time": "2025-01-27T01:40:19.109Z"
   },
   {
    "duration": 4,
    "start_time": "2025-01-27T01:40:19.113Z"
   },
   {
    "duration": 10,
    "start_time": "2025-01-27T01:40:19.119Z"
   },
   {
    "duration": 132,
    "start_time": "2025-01-27T01:40:19.131Z"
   },
   {
    "duration": 13,
    "start_time": "2025-01-27T01:40:19.265Z"
   },
   {
    "duration": 4,
    "start_time": "2025-01-27T01:40:19.279Z"
   },
   {
    "duration": 25,
    "start_time": "2025-01-27T01:40:19.286Z"
   },
   {
    "duration": 10,
    "start_time": "2025-01-27T01:40:19.312Z"
   },
   {
    "duration": 583,
    "start_time": "2025-01-27T01:40:19.323Z"
   },
   {
    "duration": 33,
    "start_time": "2025-01-27T01:40:19.908Z"
   },
   {
    "duration": 48,
    "start_time": "2025-01-27T01:40:19.943Z"
   },
   {
    "duration": 610,
    "start_time": "2025-01-27T01:40:19.993Z"
   },
   {
    "duration": 869,
    "start_time": "2025-01-27T01:40:20.605Z"
   },
   {
    "duration": 32913,
    "start_time": "2025-01-27T01:40:21.475Z"
   },
   {
    "duration": 1150,
    "start_time": "2025-01-27T01:40:54.390Z"
   },
   {
    "duration": 109,
    "start_time": "2025-01-27T01:40:55.544Z"
   },
   {
    "duration": 2838,
    "start_time": "2025-01-28T18:23:43.772Z"
   },
   {
    "duration": 26,
    "start_time": "2025-01-28T18:23:46.612Z"
   },
   {
    "duration": 32,
    "start_time": "2025-01-28T18:23:46.640Z"
   },
   {
    "duration": 4,
    "start_time": "2025-01-28T18:23:46.674Z"
   },
   {
    "duration": 3,
    "start_time": "2025-01-28T18:23:46.680Z"
   },
   {
    "duration": 10,
    "start_time": "2025-01-28T18:23:46.685Z"
   },
   {
    "duration": 193,
    "start_time": "2025-01-28T18:23:46.696Z"
   },
   {
    "duration": 8,
    "start_time": "2025-01-28T18:23:46.891Z"
   },
   {
    "duration": 5,
    "start_time": "2025-01-28T18:23:46.900Z"
   },
   {
    "duration": 44,
    "start_time": "2025-01-28T18:23:46.908Z"
   },
   {
    "duration": 3,
    "start_time": "2025-01-28T18:23:46.954Z"
   },
   {
    "duration": 574,
    "start_time": "2025-01-28T18:23:46.959Z"
   },
   {
    "duration": 35,
    "start_time": "2025-01-28T18:23:47.534Z"
   },
   {
    "duration": 37,
    "start_time": "2025-01-28T18:23:47.570Z"
   },
   {
    "duration": 650,
    "start_time": "2025-01-28T18:23:47.609Z"
   },
   {
    "duration": 868,
    "start_time": "2025-01-28T18:23:48.261Z"
   },
   {
    "duration": 33022,
    "start_time": "2025-01-28T18:23:49.131Z"
   },
   {
    "duration": 1160,
    "start_time": "2025-01-28T18:24:22.155Z"
   },
   {
    "duration": 101,
    "start_time": "2025-01-28T18:24:23.317Z"
   },
   {
    "duration": 98,
    "start_time": "2025-01-28T18:27:05.844Z"
   },
   {
    "duration": 98,
    "start_time": "2025-01-28T18:27:28.968Z"
   },
   {
    "duration": 96,
    "start_time": "2025-01-28T18:28:25.027Z"
   },
   {
    "duration": 1076,
    "start_time": "2025-01-28T18:28:51.959Z"
   },
   {
    "duration": 15,
    "start_time": "2025-01-28T18:28:53.037Z"
   },
   {
    "duration": 34,
    "start_time": "2025-01-28T18:28:53.054Z"
   },
   {
    "duration": 4,
    "start_time": "2025-01-28T18:28:53.091Z"
   },
   {
    "duration": 5,
    "start_time": "2025-01-28T18:28:53.096Z"
   },
   {
    "duration": 38,
    "start_time": "2025-01-28T18:28:53.102Z"
   },
   {
    "duration": 113,
    "start_time": "2025-01-28T18:28:53.141Z"
   },
   {
    "duration": 7,
    "start_time": "2025-01-28T18:28:53.256Z"
   },
   {
    "duration": 4,
    "start_time": "2025-01-28T18:28:53.265Z"
   },
   {
    "duration": 24,
    "start_time": "2025-01-28T18:28:53.272Z"
   },
   {
    "duration": 3,
    "start_time": "2025-01-28T18:28:53.298Z"
   },
   {
    "duration": 569,
    "start_time": "2025-01-28T18:28:53.332Z"
   },
   {
    "duration": 42,
    "start_time": "2025-01-28T18:28:53.903Z"
   },
   {
    "duration": 37,
    "start_time": "2025-01-28T18:28:53.947Z"
   },
   {
    "duration": 618,
    "start_time": "2025-01-28T18:28:53.985Z"
   },
   {
    "duration": 892,
    "start_time": "2025-01-28T18:28:54.604Z"
   },
   {
    "duration": 33125,
    "start_time": "2025-01-28T18:28:55.497Z"
   },
   {
    "duration": 1145,
    "start_time": "2025-01-28T18:29:28.624Z"
   },
   {
    "duration": 107,
    "start_time": "2025-01-28T18:29:29.770Z"
   },
   {
    "duration": 325,
    "start_time": "2025-01-28T18:34:51.572Z"
   },
   {
    "duration": 1027,
    "start_time": "2025-01-28T18:37:36.486Z"
   },
   {
    "duration": 19,
    "start_time": "2025-01-28T18:37:37.515Z"
   },
   {
    "duration": 35,
    "start_time": "2025-01-28T18:37:37.536Z"
   },
   {
    "duration": 3,
    "start_time": "2025-01-28T18:37:37.573Z"
   },
   {
    "duration": 3,
    "start_time": "2025-01-28T18:37:37.580Z"
   },
   {
    "duration": 11,
    "start_time": "2025-01-28T18:37:37.584Z"
   },
   {
    "duration": 146,
    "start_time": "2025-01-28T18:37:37.597Z"
   },
   {
    "duration": 7,
    "start_time": "2025-01-28T18:37:37.745Z"
   },
   {
    "duration": 4,
    "start_time": "2025-01-28T18:37:37.754Z"
   },
   {
    "duration": 25,
    "start_time": "2025-01-28T18:37:37.759Z"
   },
   {
    "duration": 3,
    "start_time": "2025-01-28T18:37:37.786Z"
   },
   {
    "duration": 594,
    "start_time": "2025-01-28T18:37:37.791Z"
   },
   {
    "duration": 47,
    "start_time": "2025-01-28T18:37:38.387Z"
   },
   {
    "duration": 37,
    "start_time": "2025-01-28T18:37:38.438Z"
   },
   {
    "duration": 614,
    "start_time": "2025-01-28T18:37:38.477Z"
   },
   {
    "duration": 4,
    "start_time": "2025-01-28T18:37:39.093Z"
   },
   {
    "duration": 325,
    "start_time": "2025-01-28T18:37:39.098Z"
   },
   {
    "duration": 250,
    "start_time": "2025-01-28T18:37:39.426Z"
   },
   {
    "duration": 0,
    "start_time": "2025-01-28T18:37:39.678Z"
   },
   {
    "duration": 0,
    "start_time": "2025-01-28T18:37:39.678Z"
   },
   {
    "duration": 12188,
    "start_time": "2025-01-28T18:38:43.259Z"
   },
   {
    "duration": 1069,
    "start_time": "2025-01-28T18:39:58.847Z"
   },
   {
    "duration": 16,
    "start_time": "2025-01-28T18:39:59.918Z"
   },
   {
    "duration": 35,
    "start_time": "2025-01-28T18:39:59.937Z"
   },
   {
    "duration": 3,
    "start_time": "2025-01-28T18:39:59.974Z"
   },
   {
    "duration": 3,
    "start_time": "2025-01-28T18:39:59.980Z"
   },
   {
    "duration": 11,
    "start_time": "2025-01-28T18:39:59.985Z"
   },
   {
    "duration": 133,
    "start_time": "2025-01-28T18:39:59.998Z"
   },
   {
    "duration": 8,
    "start_time": "2025-01-28T18:40:00.133Z"
   },
   {
    "duration": 4,
    "start_time": "2025-01-28T18:40:00.142Z"
   },
   {
    "duration": 25,
    "start_time": "2025-01-28T18:40:00.150Z"
   },
   {
    "duration": 4,
    "start_time": "2025-01-28T18:40:00.177Z"
   },
   {
    "duration": 592,
    "start_time": "2025-01-28T18:40:00.183Z"
   },
   {
    "duration": 33,
    "start_time": "2025-01-28T18:40:00.778Z"
   },
   {
    "duration": 51,
    "start_time": "2025-01-28T18:40:00.813Z"
   },
   {
    "duration": 609,
    "start_time": "2025-01-28T18:40:00.866Z"
   },
   {
    "duration": 4,
    "start_time": "2025-01-28T18:40:01.478Z"
   },
   {
    "duration": 339,
    "start_time": "2025-01-28T18:40:01.483Z"
   },
   {
    "duration": 12111,
    "start_time": "2025-01-28T18:40:01.823Z"
   },
   {
    "duration": 1155,
    "start_time": "2025-01-28T18:40:13.936Z"
   },
   {
    "duration": 106,
    "start_time": "2025-01-28T18:40:15.093Z"
   },
   {
    "duration": 1150,
    "start_time": "2025-01-28T18:43:12.232Z"
   },
   {
    "duration": 97,
    "start_time": "2025-01-28T18:43:16.722Z"
   },
   {
    "duration": 1707,
    "start_time": "2025-01-28T18:43:25.840Z"
   },
   {
    "duration": 160,
    "start_time": "2025-01-28T18:43:31.238Z"
   },
   {
    "duration": 2068,
    "start_time": "2025-01-28T18:43:41.454Z"
   },
   {
    "duration": 175,
    "start_time": "2025-01-28T18:43:46.396Z"
   },
   {
    "duration": 1082,
    "start_time": "2025-01-28T18:52:56.755Z"
   },
   {
    "duration": 16,
    "start_time": "2025-01-28T18:52:57.839Z"
   },
   {
    "duration": 35,
    "start_time": "2025-01-28T18:52:57.857Z"
   },
   {
    "duration": 16,
    "start_time": "2025-01-28T18:52:57.894Z"
   },
   {
    "duration": 4,
    "start_time": "2025-01-28T18:52:57.913Z"
   },
   {
    "duration": 14,
    "start_time": "2025-01-28T18:52:57.918Z"
   },
   {
    "duration": 129,
    "start_time": "2025-01-28T18:52:57.934Z"
   },
   {
    "duration": 9,
    "start_time": "2025-01-28T18:52:58.064Z"
   },
   {
    "duration": 4,
    "start_time": "2025-01-28T18:52:58.074Z"
   },
   {
    "duration": 42,
    "start_time": "2025-01-28T18:52:58.080Z"
   },
   {
    "duration": 3,
    "start_time": "2025-01-28T18:52:58.124Z"
   },
   {
    "duration": 569,
    "start_time": "2025-01-28T18:52:58.128Z"
   },
   {
    "duration": 46,
    "start_time": "2025-01-28T18:52:58.699Z"
   },
   {
    "duration": 39,
    "start_time": "2025-01-28T18:52:58.748Z"
   },
   {
    "duration": 616,
    "start_time": "2025-01-28T18:52:58.789Z"
   },
   {
    "duration": 4,
    "start_time": "2025-01-28T18:52:59.409Z"
   },
   {
    "duration": 330,
    "start_time": "2025-01-28T18:52:59.415Z"
   },
   {
    "duration": 12180,
    "start_time": "2025-01-28T18:52:59.747Z"
   },
   {
    "duration": 2070,
    "start_time": "2025-01-28T18:53:11.929Z"
   },
   {
    "duration": 188,
    "start_time": "2025-01-28T18:53:14.001Z"
   },
   {
    "duration": 2699,
    "start_time": "2025-01-30T03:34:31.353Z"
   },
   {
    "duration": 28,
    "start_time": "2025-01-30T03:34:34.055Z"
   },
   {
    "duration": 34,
    "start_time": "2025-01-30T03:34:34.085Z"
   },
   {
    "duration": 3,
    "start_time": "2025-01-30T03:34:34.122Z"
   },
   {
    "duration": 4,
    "start_time": "2025-01-30T03:34:34.126Z"
   },
   {
    "duration": 11,
    "start_time": "2025-01-30T03:34:34.132Z"
   },
   {
    "duration": 133,
    "start_time": "2025-01-30T03:34:34.145Z"
   },
   {
    "duration": 7,
    "start_time": "2025-01-30T03:34:34.280Z"
   },
   {
    "duration": 4,
    "start_time": "2025-01-30T03:34:34.289Z"
   },
   {
    "duration": 25,
    "start_time": "2025-01-30T03:34:34.295Z"
   },
   {
    "duration": 4,
    "start_time": "2025-01-30T03:34:34.321Z"
   },
   {
    "duration": 590,
    "start_time": "2025-01-30T03:34:34.327Z"
   },
   {
    "duration": 33,
    "start_time": "2025-01-30T03:34:34.919Z"
   },
   {
    "duration": 48,
    "start_time": "2025-01-30T03:34:34.953Z"
   },
   {
    "duration": 608,
    "start_time": "2025-01-30T03:34:35.003Z"
   },
   {
    "duration": 4,
    "start_time": "2025-01-30T03:34:35.613Z"
   },
   {
    "duration": 342,
    "start_time": "2025-01-30T03:34:35.620Z"
   },
   {
    "duration": 12100,
    "start_time": "2025-01-30T03:34:35.964Z"
   },
   {
    "duration": 723,
    "start_time": "2025-01-30T03:34:48.070Z"
   },
   {
    "duration": 164,
    "start_time": "2025-01-30T03:34:48.794Z"
   },
   {
    "duration": 156,
    "start_time": "2025-01-30T03:35:04.802Z"
   },
   {
    "duration": 983,
    "start_time": "2025-01-30T03:35:44.057Z"
   },
   {
    "duration": 15,
    "start_time": "2025-01-30T03:35:45.042Z"
   },
   {
    "duration": 40,
    "start_time": "2025-01-30T03:35:45.059Z"
   },
   {
    "duration": 3,
    "start_time": "2025-01-30T03:35:45.101Z"
   },
   {
    "duration": 4,
    "start_time": "2025-01-30T03:35:45.106Z"
   },
   {
    "duration": 11,
    "start_time": "2025-01-30T03:35:45.111Z"
   },
   {
    "duration": 130,
    "start_time": "2025-01-30T03:35:45.123Z"
   },
   {
    "duration": 17,
    "start_time": "2025-01-30T03:35:45.255Z"
   },
   {
    "duration": 4,
    "start_time": "2025-01-30T03:35:45.274Z"
   },
   {
    "duration": 33,
    "start_time": "2025-01-30T03:35:45.282Z"
   },
   {
    "duration": 3,
    "start_time": "2025-01-30T03:35:45.317Z"
   },
   {
    "duration": 576,
    "start_time": "2025-01-30T03:35:45.322Z"
   },
   {
    "duration": 33,
    "start_time": "2025-01-30T03:35:45.900Z"
   },
   {
    "duration": 49,
    "start_time": "2025-01-30T03:35:45.934Z"
   },
   {
    "duration": 632,
    "start_time": "2025-01-30T03:35:45.984Z"
   },
   {
    "duration": 4,
    "start_time": "2025-01-30T03:35:46.618Z"
   },
   {
    "duration": 334,
    "start_time": "2025-01-30T03:35:46.624Z"
   },
   {
    "duration": 12048,
    "start_time": "2025-01-30T03:35:46.961Z"
   },
   {
    "duration": 728,
    "start_time": "2025-01-30T03:35:59.011Z"
   },
   {
    "duration": 167,
    "start_time": "2025-01-30T03:35:59.741Z"
   },
   {
    "duration": 981,
    "start_time": "2025-01-30T03:36:39.228Z"
   },
   {
    "duration": 15,
    "start_time": "2025-01-30T03:36:40.212Z"
   },
   {
    "duration": 42,
    "start_time": "2025-01-30T03:36:40.228Z"
   },
   {
    "duration": 3,
    "start_time": "2025-01-30T03:36:40.272Z"
   },
   {
    "duration": 3,
    "start_time": "2025-01-30T03:36:40.277Z"
   },
   {
    "duration": 10,
    "start_time": "2025-01-30T03:36:40.282Z"
   },
   {
    "duration": 131,
    "start_time": "2025-01-30T03:36:40.294Z"
   },
   {
    "duration": 8,
    "start_time": "2025-01-30T03:36:40.426Z"
   },
   {
    "duration": 5,
    "start_time": "2025-01-30T03:36:40.435Z"
   },
   {
    "duration": 40,
    "start_time": "2025-01-30T03:36:40.441Z"
   },
   {
    "duration": 3,
    "start_time": "2025-01-30T03:36:40.483Z"
   },
   {
    "duration": 575,
    "start_time": "2025-01-30T03:36:40.488Z"
   },
   {
    "duration": 34,
    "start_time": "2025-01-30T03:36:41.069Z"
   },
   {
    "duration": 36,
    "start_time": "2025-01-30T03:36:41.106Z"
   },
   {
    "duration": 621,
    "start_time": "2025-01-30T03:36:41.143Z"
   },
   {
    "duration": 889,
    "start_time": "2025-01-30T03:36:41.770Z"
   },
   {
    "duration": 328,
    "start_time": "2025-01-30T03:36:42.661Z"
   },
   {
    "duration": 12064,
    "start_time": "2025-01-30T03:36:42.991Z"
   },
   {
    "duration": 725,
    "start_time": "2025-01-30T03:36:55.058Z"
   },
   {
    "duration": 163,
    "start_time": "2025-01-30T03:36:55.784Z"
   },
   {
    "duration": 2254,
    "start_time": "2025-01-30T03:39:32.788Z"
   },
   {
    "duration": 181,
    "start_time": "2025-01-30T03:41:45.099Z"
   },
   {
    "duration": 1005,
    "start_time": "2025-01-30T03:42:29.052Z"
   },
   {
    "duration": 16,
    "start_time": "2025-01-30T03:42:30.059Z"
   },
   {
    "duration": 34,
    "start_time": "2025-01-30T03:42:30.076Z"
   },
   {
    "duration": 4,
    "start_time": "2025-01-30T03:42:30.111Z"
   },
   {
    "duration": 3,
    "start_time": "2025-01-30T03:42:30.119Z"
   },
   {
    "duration": 10,
    "start_time": "2025-01-30T03:42:30.124Z"
   },
   {
    "duration": 137,
    "start_time": "2025-01-30T03:42:30.136Z"
   },
   {
    "duration": 9,
    "start_time": "2025-01-30T03:42:30.274Z"
   },
   {
    "duration": 4,
    "start_time": "2025-01-30T03:42:30.284Z"
   },
   {
    "duration": 27,
    "start_time": "2025-01-30T03:42:30.291Z"
   },
   {
    "duration": 4,
    "start_time": "2025-01-30T03:42:30.321Z"
   },
   {
    "duration": 585,
    "start_time": "2025-01-30T03:42:30.327Z"
   },
   {
    "duration": 34,
    "start_time": "2025-01-30T03:42:30.914Z"
   },
   {
    "duration": 52,
    "start_time": "2025-01-30T03:42:30.951Z"
   },
   {
    "duration": 613,
    "start_time": "2025-01-30T03:42:31.005Z"
   },
   {
    "duration": 872,
    "start_time": "2025-01-30T03:42:31.619Z"
   },
   {
    "duration": 325,
    "start_time": "2025-01-30T03:42:32.493Z"
   },
   {
    "duration": 12051,
    "start_time": "2025-01-30T03:42:32.819Z"
   },
   {
    "duration": 729,
    "start_time": "2025-01-30T03:42:44.871Z"
   },
   {
    "duration": 2297,
    "start_time": "2025-01-30T03:42:45.601Z"
   },
   {
    "duration": 191,
    "start_time": "2025-01-30T03:42:47.899Z"
   },
   {
    "duration": 187,
    "start_time": "2025-01-30T03:42:48.092Z"
   },
   {
    "duration": 157,
    "start_time": "2025-01-30T18:53:20.650Z"
   },
   {
    "duration": 2730,
    "start_time": "2025-01-30T18:53:27.168Z"
   },
   {
    "duration": 27,
    "start_time": "2025-01-30T18:53:29.901Z"
   },
   {
    "duration": 34,
    "start_time": "2025-01-30T18:53:29.929Z"
   },
   {
    "duration": 3,
    "start_time": "2025-01-30T18:53:29.965Z"
   },
   {
    "duration": 4,
    "start_time": "2025-01-30T18:53:29.971Z"
   },
   {
    "duration": 10,
    "start_time": "2025-01-30T18:53:29.977Z"
   },
   {
    "duration": 134,
    "start_time": "2025-01-30T18:53:29.989Z"
   },
   {
    "duration": 8,
    "start_time": "2025-01-30T18:53:30.126Z"
   },
   {
    "duration": 4,
    "start_time": "2025-01-30T18:53:30.136Z"
   },
   {
    "duration": 96,
    "start_time": "2025-01-30T18:53:30.142Z"
   },
   {
    "duration": 4,
    "start_time": "2025-01-30T18:53:30.239Z"
   },
   {
    "duration": 566,
    "start_time": "2025-01-30T18:53:30.244Z"
   },
   {
    "duration": 42,
    "start_time": "2025-01-30T18:53:30.812Z"
   },
   {
    "duration": 35,
    "start_time": "2025-01-30T18:53:30.858Z"
   },
   {
    "duration": 624,
    "start_time": "2025-01-30T18:53:30.895Z"
   },
   {
    "duration": 12,
    "start_time": "2025-01-30T18:53:31.524Z"
   },
   {
    "duration": 326,
    "start_time": "2025-01-30T18:53:31.538Z"
   },
   {
    "duration": 12047,
    "start_time": "2025-01-30T18:53:31.866Z"
   },
   {
    "duration": 728,
    "start_time": "2025-01-30T18:53:43.915Z"
   },
   {
    "duration": 3035,
    "start_time": "2025-01-30T18:53:44.645Z"
   },
   {
    "duration": 201,
    "start_time": "2025-01-30T18:53:47.683Z"
   },
   {
    "duration": 199,
    "start_time": "2025-01-30T18:53:47.887Z"
   },
   {
    "duration": 3009,
    "start_time": "2025-01-30T18:54:41.545Z"
   },
   {
    "duration": 196,
    "start_time": "2025-01-30T18:55:08.438Z"
   },
   {
    "duration": 12,
    "start_time": "2025-01-30T18:57:37.641Z"
   },
   {
    "duration": 913,
    "start_time": "2025-01-30T18:58:14.272Z"
   },
   {
    "duration": 163,
    "start_time": "2025-01-30T18:58:42.718Z"
   }
  ],
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": true,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
